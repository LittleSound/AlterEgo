import type { Context } from 'grammy'
import type { Message } from 'grammy/types'
import type { Tool } from 'xsai'
import type { AppEnv } from './env'
import { GrammyError } from 'grammy'
import { streamText } from 'xsai'
import { cleanAIResponse, convertToTelegramHtml, formatMessage, formatName } from './format'
import { defineLogStreamed, error, getVerboseMode, log } from './log'
import { systemPrompt } from './prompt'
import { getChatHistory, getSessionMemoryStats, recordAssistantText, recordUserText } from './session'
import { getFormatedMemoriesMessage, remember } from './tool/memory'
import { invoke } from './utils'

const EDIT_MESSAGE_INTERVAL = 1000

// å½“ AI æ”¶åˆ°ç”¨æˆ·çš„æ¶ˆæ¯æ—¶ï¼Œæ¯”å¦‚ç›´æŽ¥ç§èŠï¼Œæˆ–è€…æ˜¯åœ¨ç¾¤é‡Œ @ å®ƒï¼Œæˆ–è€…å›žå¤å®ƒ
// å®ƒä¼šé€šè¿‡è¿™ä¸ªå‡½æ•°ç»™å‡ºç­”å¤ï¼Œå¹¶ä¸”æŠŠå¯¹è¯è®°å½•å­˜å‚¨åˆ°å†…å­˜ä¸­
// LLM ç”Ÿæˆçš„æ¶ˆæ¯ä¼šä¸€ç‚¹ä¸€ç‚¹åœ°å‘é€ç»™ç”¨æˆ·ï¼Œå°±åƒæµå¼ä¼ è¾“ä¸€æ ·
export function replyMessageWithAI(options: {
  ctx: Context
  env: AppEnv
  aiTools: Tool[]
}) {
  const { ctx, env, aiTools } = options

  const requestMsg = ctx.msg

  if (!requestMsg || !ctx.chat?.id)
    return

  let theMsg: Message.TextMessage
  // æ˜¯å¦æœ‰ function calling
  let isWithWorking = false
  let isThinking = false

  const requestMsgText = formatMessage(requestMsg)
  const userName = formatName(ctx.from)
  const userId = ctx.from?.id || 0
  const replyTextList: string[] = []
  const toolCalls: { toolName: string, args: string }[] = []

  log(`[MSG] ${userName} (${userId}) in ${ctx.chat.type}:`, requestMsgText)

  // å›žå¤çš„æ¶ˆæ¯ï¼Œä¿®æ”¹è¿™ä¸ªå€¼ä¼šç›´æŽ¥å‘é€æˆ–ä¿®æ”¹è¿™æ¡æ¶ˆæ¯
  const replyMessage = invoke(() => {
    let value = ''
    let oldValue = ''

    let lastUpdateTime = 0
    let throttleTimer: Timer | null = null

    return {
      get value() {
        return value
      },
      set value(text: string) {
        if (!text || text.trim() === '')
          return
        value = convertToTelegramHtml(text)

        if (!theMsg && lastUpdateTime === 0) {
          newMessage(value)
          lastUpdateTime = Date.now()
          oldValue = value
          return
        }

        const now = Date.now()
        const timeSinceLastUpdate = now - lastUpdateTime

        if (timeSinceLastUpdate >= EDIT_MESSAGE_INTERVAL) {
          // å¯ä»¥ç«‹å³æ›´æ–°
          editMessage(value, oldValue)
          lastUpdateTime = now
          oldValue = value
        }
        else {
          if (!throttleTimer) {
            // è®¾ç½®å®šæ—¶å™¨ï¼Œåœ¨ä¸‹ä¸ªæ—¶é—´çª—å£æ›´æ–°
            const delay = EDIT_MESSAGE_INTERVAL - timeSinceLastUpdate
            throttleTimer = setTimeout(() => {
              if (value) {
                editMessage(value, oldValue)
                lastUpdateTime = Date.now()
                oldValue = value
              }
              throttleTimer = null
            }, delay)
          }
        }
      },
    }

    async function newMessage(newValue: string) {
      try {
        // å¦‚æžœæ˜¯ @ æˆ–å›žå¤ï¼Œåˆ™å›žå¤åŽŸæ¶ˆæ¯
        const shouldReplyToMessage = requestMsg?.text?.includes('@') || requestMsg?.reply_to_message
        theMsg = await ctx.reply(newValue, {
          reply_parameters: shouldReplyToMessage && requestMsg?.message_id
            ? { message_id: requestMsg.message_id }
            : undefined,
          parse_mode: 'HTML',
        })
      }
      catch (err) {
        // ç”¨æˆ·å¯èƒ½å±è”½äº†æœºå™¨äººï¼Œæˆ–å…¶ä»–å‘é€æ¶ˆæ¯å¤±è´¥çš„æƒ…å†µ
        if (err instanceof GrammyError && err.error_code === 403) {
          error('User blocked the bot:', userId)
          return
        }
        throw err
      }
    }

    async function editMessage(newValue: string, oldValue: string) {
      if (newValue === oldValue)
        return

      if (!theMsg) {
        error('Cannot edit message: theMsg is undefined')
        return
      }

      try {
        await ctx.api.editMessageText(
          theMsg.chat.id,
          theMsg.message_id,
          newValue,
          { parse_mode: 'HTML' },
        )
      }
      catch (err) {
        // å¿½ç•¥"å†…å®¹æœªä¿®æ”¹"çš„é”™è¯¯ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        if (err instanceof GrammyError && err.description.includes('message is not modified')) {
          return
        }
        throw err
      }
    }
  })

  function getToolsLog() {
    return toolCalls.filter(Boolean).map((t) => {
      const args = t.args.length > 32 ? `${t.args.slice(0, 32)}...` : t.args
      return `âš™ï¸ ${t.toolName} \`${args.replaceAll('\n', ' ').replaceAll('`', '')}\``
    }).join('\n')
  }

  function createReplyProcessText() {
    const cleanedPartial = replyTextList.length ? cleanAIResponse(replyTextList.join('')) : ''
    let text = ''
    if (isWithWorking) {
      text += `ðŸŸ  Working...\n${getToolsLog()}`
    }
    else if (isThinking && !cleanedPartial.length) {
      text += 'ðŸŸ¢ Thinking...'
    }
    else {
      text += 'ðŸŸ¢ Typing...'
    }
    if (cleanedPartial.length) {
      text += `\n\n${cleanedPartial}${'...'}`
    }
    return text
  }

  function handleError(err: unknown) {
    error('Error processing message:', err)
    const errorText = 'ðŸ”´ Something went wrong. I don\'t know what to say next...'
    if (theMsg) {
      const hasSomeMessage = replyTextList.length > 0 || toolCalls.length > 0
      const finalErrorMsg = hasSomeMessage
        ? `${createReplyProcessText()}\n\n${errorText}`
        : errorText

      // è®© AI çŸ¥é“è‡ªå·±å‡ºé”™äº†ã€‚ç”¨æˆ·é—®çš„æ—¶å€™ï¼ŒAI å¯ä»¥å›žç­”ä¸ºä»€ä¹ˆå‡ºé”™äº†ã€‚
      recordAssistantText(ctx, err instanceof Error
        ? `${finalErrorMsg}\n\nAlter Ego System Error Log: ${err.toString()}`
        : finalErrorMsg)
      replyMessage.value = finalErrorMsg
    }
    else {
      // è®© AI çŸ¥é“è‡ªå·±å‡ºé”™äº†ã€‚ç”¨æˆ·é—®çš„æ—¶å€™ï¼ŒAI å¯ä»¥å›žç­”ä¸ºä»€ä¹ˆå‡ºé”™äº†ã€‚
      recordAssistantText(ctx, err instanceof Error
        ? `${errorText}\n\nAlter Ego System Error Log: ${err.toString()}`
        : errorText)
      replyMessage.value = errorText
    }
  }

  invoke(async () => {
    replyMessage.value = 'ðŸ”µ Connecting...'

    recordUserText(ctx, requestMsgText)
    const chatHistory = getChatHistory(ctx)
    const messages = systemPrompt({ userName, chatType: ctx.chat?.type })
    const memories = getFormatedMemoriesMessage(userId, userName)
    if (memories)
      messages.push(memories)
    messages.push(...chatHistory)

    const { textStream } = streamText({
      apiKey: env.AI_OPENROUTER_API_KEY!,
      baseURL: env.AI_OPENROUTER_BASE_URL,
      messages,
      model: env.AI_LLM_DEFAULT_MODEL,
      maxSteps: env.AI_LLM_MAX_STEPS,
      tools: [
        ...aiTools,
        await remember({ userId }),
      ],
      onEvent(event) {
        if (!isWithWorking && event.type === 'tool-call-delta') {
          isWithWorking = true
        }
        if (!isThinking && event.type === 'text-delta' && event.text === '') {
          isThinking = true
        }
        if (event.type !== 'tool-call') {
          return
        }
        isWithWorking = true

        log(`[TOOL] Calling tool: ${event.toolName} with args: ${event.args}`)
        toolCalls.push({ toolName: event.toolName, args: event.args })

        replyMessage.value = createReplyProcessText()
      },
    })

    const writeLog = defineLogStreamed('[REPLY] Alter Ego: ')
    for await (const textPart of textStream) {
      replyTextList.push(textPart)
      writeLog(textPart)

      replyMessage.value = createReplyProcessText()
    }
    writeLog('\n')

    const finalResponse = cleanAIResponse(replyTextList.join(''))
    // log(`[REPLY] Alter Ego:`, finalResponse)
    recordAssistantText(ctx, finalResponse)
    replyMessage.value = isWithWorking
      ? `â˜‘ï¸ Done working\n${finalResponse}`
      : finalResponse
  }).catch(async (err) => {
    handleError(err)
  }).finally(() => {
    // è¾“å‡ºå†…å­˜ç»Ÿè®¡
    if (!getVerboseMode())
      return
    try {
      const stats = getSessionMemoryStats()
      log(`[MEMORY] Sessions: ${stats.sessionsCount}, Total messages: ${stats.totalMessages}`)
    }
    catch (err) {
      error('Unexpected error when processing message:', err)
    }
  })
}
